import json
import requests
import sys
import os
import datetime

# --- Configuration ---
CONFIG_FILE = "config.json"

def load_config():
    """Loads configuration from config.json"""
    try:
        with open(CONFIG_FILE, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: Configuration file '{CONFIG_FILE}' not found.", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{CONFIG_FILE}'.", file=sys.stderr)
        sys.exit(1)

config_data = load_config()
AI_API_URL = config_data.get("ai_api_url", "http://localhost:11434/api/generate")
AI_API_KEY = config_data.get("ai_api_key") # Can be None
AI_API_TIMEOUT = config_data.get("ai_api_timeout", 120)
ANALYSIS_PROFILES = config_data.get("analysis_profiles", {})

# The model is read from the AI_MODEL environment variable.
AI_MODEL = os.environ.get("AI_MODEL", "llama3:8b")

def get_analysis_from_llm(prompt_data):
    """
    Sends the provided data to a compatible LLM API and returns the response.
    """
    try:
        payload = {
            "model": AI_MODEL,
            "prompt": prompt_data,
            "stream": False
        }
        
        headers = {"Content-Type": "application/json"}
        if AI_API_KEY:
            headers["Authorization"] = f"Bearer {AI_API_KEY}"

        print(f"--- Contacting AI at {AI_API_URL} with model {AI_MODEL}... ---", file=sys.stderr)
        
        response = requests.post(AI_API_URL, json=payload, headers=headers, timeout=AI_API_TIMEOUT)
        response.raise_for_status()

        print("--- Received response. Generating report... ---", file=sys.stderr)
        
        response_json = response.json()
        return response_json.get("response", "").strip()

    except requests.exceptions.Timeout:
        return f"Error: The request to the AI API timed out after {AI_API_TIMEOUT} seconds."
    except requests.exceptions.RequestException as e:
        return f"Error: Could not connect to AI API at {AI_API_URL}. Please ensure the endpoint is correct and the service is running. Details: {e}"
    except json.JSONDecodeError:
        return "Error: Failed to decode JSON response from the AI API."
    except Exception as e:
        return f"An unexpected error occurred: {e}"

def main():
    """
    Main function to read data, generate a prompt from an external file, and save the analysis.
    Accepts a command-line argument for analysis type ('perf' or 'base'). Defaults to 'base'.
    """
    # Determine analysis type from command-line arguments
    if len(sys.argv) > 1 and sys.argv[1] in ANALYSIS_PROFILES:
        analysis_type = sys.argv[1]
    else:
        analysis_type = "base" # Default to base analysis
    
    profile = ANALYSIS_PROFILES.get(analysis_type, {})
    if not profile:
        print(f"Error: Analysis profile '{analysis_type}' not found in {CONFIG_FILE}.", file=sys.stderr)
        sys.exit(1)

    data_file = profile.get("data_file")
    prompt_file = profile.get("prompt_file")
    output_prefix = profile.get("output_prefix")

    print(f"--- Running analysis type: '{analysis_type}' ---", file=sys.stderr)

    start_time = datetime.datetime.now()
    
    try:
        with open(data_file, 'r') as f:
            db_stats_json_string = f.read()
            db_stats = json.loads(db_stats_json_string)
    except FileNotFoundError:
        print(f"Error: The file '{data_file}' was not found.", file=sys.stderr)
        print(f"Please run the corresponding SQL script first (e.g., `psql -f {data_file.replace('.json', '.sql')}`).", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{data_file}'. The file might be empty or malformed.", file=sys.stderr)
        sys.exit(1)

    try:
        with open(prompt_file, 'r') as f:
            prompt_template = f.read()
    except FileNotFoundError:
        print(f"Error: Prompt file '{prompt_file}' not found.", file=sys.stderr)
        sys.exit(1)

    # Construct the full prompt
    full_prompt = prompt_template.format(rag_context="", json_data=db_stats_json_string)

    # Get the analysis
    analysis = get_analysis_from_llm(full_prompt)
    
    end_time = datetime.datetime.now()

    # --- File Generation ---
    database_name = db_stats.get("metadata", {}).get("database_name", "unknown_db")
    timestamp_str = start_time.strftime("%Y%m%d_%H%M%S")
    output_filename = f"{output_prefix}.{database_name}.{timestamp_str}.md"

    # --- Footer ---
    footer = "\n---\n"
    footer += f"*Report generated by pg_aidba ({analysis_type}) on {start_time.strftime('%Y-%m-%d at %H:%M:%S')}*\n"
    footer += f"*Model used: `{AI_MODEL}`*\n"
    footer += f"*Analysis duration: {(end_time - start_time).total_seconds():.2f} seconds*\n"
    footer += f"*License: Apache 2.0 (meob)*\n"

    final_report = analysis + "\n" + footer

    try:
        with open(output_filename, 'w') as f:
            f.write(final_report)
        print(f"--- Report successfully saved to '{output_filename}' ---", file=sys.stderr)
    except IOError as e:
        print(f"Error: Could not write report to file '{output_filename}'. Details: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()